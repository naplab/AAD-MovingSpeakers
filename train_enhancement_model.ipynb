{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc3ddd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import yaml\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from src.data_utilities import EnhancementDataset\n",
    "from src.loss_utilities import snr_loss\n",
    "from models import EnhancementNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dccc32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d042814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--checkpoint-path'], dest='checkpoint_path', nargs=None, const=None, default='/engram/naplab/users/ch3212/NMI/enh', type=<class 'str'>, choices=None, required=False, help='path to save the model', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='enh')\n",
    "\n",
    "parser.add_argument('--batch-size', type=int, default=6,\n",
    "                    help='input batch size for training')\n",
    "parser.add_argument('--epochs', type=int, default=100,\n",
    "                    help='number of epochs to train')\n",
    "parser.add_argument('--cuda', action='store_true', default=True,\n",
    "                    help='enables CUDA training')\n",
    "parser.add_argument('--lr', type=float, default=1e-3,\n",
    "                    help='learning rate')\n",
    "parser.add_argument('--config', default='./configs/config_enhancement.yaml', type=str,\n",
    "                    help='model config')\n",
    "parser.add_argument('--seed', type=int, default=2023028,\n",
    "                    help='random seed')\n",
    "parser.add_argument('--training-file-path', default='/engram/naplab/users/ch3212/google_moving_large_stage2/tr', type=str,\n",
    "                    help='training file path')\n",
    "parser.add_argument('--validation-file-path', default='/engram/naplab/users/ch3212/google_moving_large_stage2/cv', type=str,\n",
    "                    help='validation file path')\n",
    "parser.add_argument('--checkpoint-path', type=str,  default='/engram/naplab/users/ch3212/NMI/enh',\n",
    "                    help='path to save the model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7ca8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(path):\n",
    "    with open(path, 'r') as ymlfile:\n",
    "        config = yaml.safe_load(ymlfile)\n",
    "    return config\n",
    "\n",
    "\n",
    "def save_checkpoint(filepath, obj):\n",
    "    print(\"Saving checkpoint to {}\".format(filepath))\n",
    "    torch.save(obj, filepath)\n",
    "    print(\"Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4233f627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, validation_loader, model, optimizer, scheduler, summary_writer, args):\n",
    "   \n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            batch_s1 = Variable(data[0]).contiguous()\n",
    "            batch_s2 = Variable(data[1]).contiguous()\n",
    "            batch_est_s1 = Variable(data[2]).contiguous()\n",
    "            batch_est_s2 = Variable(data[3]).contiguous()\n",
    "            batch_noise = Variable(data[4]).contiguous()\n",
    "            batch_mix = batch_s1 + batch_s2 + batch_noise\n",
    "\n",
    "            if args.cuda:\n",
    "                batch_mix = batch_mix.cuda()\n",
    "                batch_s1 = batch_s1.cuda()\n",
    "                batch_s2 = batch_s2.cuda()\n",
    "                batch_est_s1 = batch_est_s1.cuda()\n",
    "                batch_est_s2 = batch_est_s2.cuda()\n",
    "                \n",
    "            batch_mix = torch.cat([batch_mix, batch_mix], dim=0)\n",
    "            batch_est = torch.cat([batch_est_s1, batch_est_s2], dim=0)\n",
    "            batch_clean = torch.cat([batch_s1, batch_s2], dim=0)\n",
    "            batch_output = model(batch_mix, batch_est)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = torch.mean(snr_loss(batch_clean.view(batch_clean.size(0)*2, batch_clean.size(2)), \n",
    "                                       batch_output.view(batch_clean.size(0)*2, batch_clean.size(2)))\n",
    "                             )   \n",
    "                \n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 5.)\n",
    "            train_loss += loss.data.item() \n",
    "            optimizer.step()\n",
    "            \n",
    "        train_loss /= (batch_idx+1)\n",
    "        \n",
    "        print('train', epoch, train_loss)\n",
    "        \n",
    "        summary_writer.add_scalar(\"training/train_loss\", train_loss, epoch)\n",
    "        \n",
    "        checkpoint_path = \"{}/epoch_{:03d}\".format(args.checkpoint_path, epoch)\n",
    "        \n",
    "        save_checkpoint(\n",
    "            checkpoint_path,\n",
    "            {\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        })\n",
    "        \n",
    "        \n",
    "        model.eval()\n",
    "        validation_loss = 0.\n",
    "        \n",
    "        for batch_idx, data in enumerate(validation_loader):\n",
    "            batch_s1 = Variable(data[0]).contiguous()\n",
    "            batch_s2 = Variable(data[1]).contiguous()\n",
    "            batch_est_s1 = Variable(data[2]).contiguous()\n",
    "            batch_est_s2 = Variable(data[3]).contiguous()\n",
    "            batch_noise = Variable(data[4]).contiguous()\n",
    "            batch_mix = batch_s1 + batch_s2 + batch_noise\n",
    "\n",
    "            if args.cuda:\n",
    "                batch_mix = batch_mix.cuda()\n",
    "                batch_s1 = batch_s1.cuda()\n",
    "                batch_s2 = batch_s2.cuda()\n",
    "                batch_est_s1 = batch_est_s1.cuda()\n",
    "                batch_est_s2 = batch_est_s2.cuda()\n",
    "                \n",
    "            batch_mix = torch.cat([batch_mix, batch_mix], dim=0)\n",
    "            batch_est = torch.cat([batch_est_s1, batch_est_s2], dim=0)\n",
    "            batch_clean = torch.cat([batch_s1, batch_s2], dim=0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                batch_output = model(batch_mix, batch_est)\n",
    "                loss = torch.mean(snr_loss(batch_clean.view(batch_clean.size(0)*2, batch_clean.size(2)), \n",
    "                                           batch_output.view(batch_clean.size(0)*2, batch_clean.size(2)))\n",
    "                                 )  \n",
    "\n",
    "                validation_loss += loss.data.item() \n",
    "                \n",
    "        validation_loss /= (batch_idx+1)\n",
    "        summary_writer.add_scalar(\"training/val_loss\", validation_loss, epoch)\n",
    "        \n",
    "        print('eval', epoch, validation_loss)\n",
    "        \n",
    "        if epoch % 2 == 0:\n",
    "            scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2c60d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2b8e74feef90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "args.cuda = args.cuda and torch.cuda.is_available()\n",
    "\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    kwargs = {'num_workers': 4, 'pin_memory': True} \n",
    "else:\n",
    "    kwargs = {}\n",
    "    \n",
    "random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d2a0dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(EnhancementDataset(args.training_file_path), \n",
    "                          batch_size=args.batch_size, \n",
    "                          shuffle=True, \n",
    "                          **kwargs)\n",
    "\n",
    "\n",
    "validation_loader = DataLoader(EnhancementDataset(args.validation_file_path), \n",
    "                               batch_size=args.batch_size, \n",
    "                               shuffle=False, \n",
    "                               **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad98696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77d9f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(args.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f11f77ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receptive field: 1271 frames.\n"
     ]
    }
   ],
   "source": [
    "model = EnhancementNet(\n",
    "    enc_dim = config['enc_dim'],\n",
    "    feature_dim = config['feature_dim'],\n",
    "    hidden_dim = config['hidden_dim'],\n",
    "    enc_win = config['enc_win'],\n",
    "    enc_stride = config['enc_stride'],\n",
    "    num_block = config['num_block'],\n",
    "    num_layer = config['num_layer'],\n",
    "    kernel_size = config['kernel_size'],\n",
    "    num_spk = config['num_spk'],\n",
    ")\n",
    "\n",
    "if args.cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d66ddd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "scheduler  = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4722ecdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = SummaryWriter(os.path.join(args.checkpoint_path, 'logs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9d72c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1 -11.376143914057561\n",
      "Saving checkpoint to /engram/naplab/users/ch3212/NMI/enh/epoch_001\n",
      "Complete.\n",
      "eval 1 -12.099213304519653\n",
      "train 2 -12.957555113077163\n",
      "Saving checkpoint to /engram/naplab/users/ch3212/NMI/enh/epoch_002\n",
      "Complete.\n",
      "eval 2 -12.840064935684204\n",
      "train 3 -13.495704421758651\n",
      "Saving checkpoint to /engram/naplab/users/ch3212/NMI/enh/epoch_003\n",
      "Complete.\n",
      "eval 3 -13.191324367523194\n",
      "train 4 -13.828021122217178\n",
      "Saving checkpoint to /engram/naplab/users/ch3212/NMI/enh/epoch_004\n",
      "Complete.\n",
      "eval 4 -13.37281294822693\n",
      "train 5 -14.090777539491654\n",
      "Saving checkpoint to /engram/naplab/users/ch3212/NMI/enh/epoch_005\n",
      "Complete.\n",
      "eval 5 -13.637734718322754\n",
      "train 6 -14.291232374429702\n",
      "Saving checkpoint to /engram/naplab/users/ch3212/NMI/enh/epoch_006\n",
      "Complete.\n",
      "eval 6 -13.749120535850524\n",
      "train 7 -14.472587305545806\n",
      "Saving checkpoint to /engram/naplab/users/ch3212/NMI/enh/epoch_007\n",
      "Complete.\n",
      "eval 7 -13.849336700439453\n",
      "train 8 -14.62489506649971\n",
      "Saving checkpoint to /engram/naplab/users/ch3212/NMI/enh/epoch_008\n",
      "Complete.\n",
      "eval 8 -13.919208154678344\n",
      "train 9 -14.761653050661087\n",
      "Saving checkpoint to /engram/naplab/users/ch3212/NMI/enh/epoch_009\n",
      "Complete.\n",
      "eval 9 -13.971700940132141\n",
      "train 10 -14.87379413485527\n",
      "Saving checkpoint to /engram/naplab/users/ch3212/NMI/enh/epoch_010\n",
      "Complete.\n",
      "eval 10 -14.07031536102295\n",
      "train 11 -14.992091680765151\n",
      "Saving checkpoint to /engram/naplab/users/ch3212/NMI/enh/epoch_011\n",
      "Complete.\n",
      "eval 11 -14.195234842300415\n",
      "train 12 -15.076377795219422\n",
      "Saving checkpoint to /engram/naplab/users/ch3212/NMI/enh/epoch_012\n",
      "Complete.\n",
      "eval 12 -14.232624735832214\n"
     ]
    }
   ],
   "source": [
    "train(train_loader, validation_loader, model, optimizer, scheduler, sw, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f9410b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028c6dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc63071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
